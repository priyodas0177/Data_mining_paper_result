{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"19CDDldPZ_w_etHcYidTfMsqV-z9TwZSn","authorship_tag":"ABX9TyPABySQxIE/i7i25Zsd4xEB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YT04isT_8oQE","executionInfo":{"status":"ok","timestamp":1750437407078,"user_tz":-360,"elapsed":10163,"user":{"displayName":"Faria Ahmed Richi","userId":"06940165953230423654"}},"outputId":"c83437cb-d497-4c87-aca4-6aa384d70804"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Final class balance:\n"," burnout\n","1    0.5\n","0    0.5\n","Name: proportion, dtype: float64\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç Logistic Regression Evaluation:\n","Accuracy: 93.06%\n","                 precision    recall  f1-score   support\n","\n","Not at risk (0)       0.92      0.91      0.92      2347\n","    At risk (1)       0.94      0.94      0.94      3118\n","\n","       accuracy                           0.93      5465\n","      macro avg       0.93      0.93      0.93      5465\n","   weighted avg       0.93      0.93      0.93      5465\n","\n","Confusion Matrix:\n"," [[2143  204]\n"," [ 175 2943]]\n","\n","üîç Decision Tree Evaluation:\n","Accuracy: 95.33%\n","                 precision    recall  f1-score   support\n","\n","Not at risk (0)       0.94      0.95      0.95      2347\n","    At risk (1)       0.96      0.96      0.96      3118\n","\n","       accuracy                           0.95      5465\n","      macro avg       0.95      0.95      0.95      5465\n","   weighted avg       0.95      0.95      0.95      5465\n","\n","Confusion Matrix:\n"," [[2231  116]\n"," [ 139 2979]]\n","\n","üîç Random Forest Evaluation:\n","Accuracy: 96.47%\n","                 precision    recall  f1-score   support\n","\n","Not at risk (0)       0.93      0.99      0.96      2347\n","    At risk (1)       0.99      0.94      0.97      3118\n","\n","       accuracy                           0.96      5465\n","      macro avg       0.96      0.97      0.96      5465\n","   weighted avg       0.97      0.96      0.96      5465\n","\n","Confusion Matrix:\n"," [[2331   16]\n"," [ 177 2941]]\n","\n","üîç XGBoost Evaluation:\n","Accuracy: 96.45%\n","                 precision    recall  f1-score   support\n","\n","Not at risk (0)       0.94      0.98      0.96      2347\n","    At risk (1)       0.98      0.95      0.97      3118\n","\n","       accuracy                           0.96      5465\n","      macro avg       0.96      0.97      0.96      5465\n","   weighted avg       0.97      0.96      0.96      5465\n","\n","Confusion Matrix:\n"," [[2301   46]\n"," [ 148 2970]]\n"]}],"source":["# üì¶ Import necessary libraries\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import SMOTE\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","from google.colab import drive, files\n","\n","# üìÇ Step 1: Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# üì• Step 2: Load Dataset\n","file_path = '/content/drive/MyDrive/Final_dataset_cleanedf.csv'\n","df = pd.read_csv(file_path)\n","\n","# üßπ Step 3: Remove negative engagement duration\n","df = df[df['engagement_duration_days'] >= 0]\n","\n","# üßæ Step 4: Encode categorical variables\n","df = pd.get_dummies(df, columns=['region', 'imd_band', 'final_result', 'disability', 'gender'], drop_first=True)\n","\n","# ‚úÇÔ∏è Step 5: Remove extreme outliers before scaling\n","numeric_features = ['avg_clicks_per_week', 'studied_credits', 'engagement_duration_days', 'total_failed_or_missed']\n","for col in numeric_features:\n","    q_low = df[col].quantile(0.01)\n","    q_high = df[col].quantile(0.99)\n","    df = df[(df[col] >= q_low) & (df[col] <= q_high)]\n","\n","# üîÑ Step 6: Standardize numeric features\n","scaler = StandardScaler()\n","df[numeric_features] = scaler.fit_transform(df[numeric_features])\n","\n","# üéØ Step 7: Separate features and target\n","X = df.drop('burnout', axis=1)\n","y = df['burnout']\n","\n","# üß™ Step 8: Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# ‚öñÔ∏è Step 9: Handle imbalance using SMOTE\n","smote = SMOTE(random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n","\n","# ‚úÖ Step 10: Final check and save\n","print(\"Final class balance:\\n\", pd.Series(y_train_resampled).value_counts(normalize=True))\n","\n","# üßΩ Step 11: Clean column names (for XGBoost compatibility)\n","cleaned_columns = X_train_resampled.columns.str.replace(r'[\\[\\]<>]', '', regex=True).str.replace(' ', '_')\n","X_train_resampled.columns = cleaned_columns\n","X_test.columns = cleaned_columns  # Ensure test set matches\n","\n","# üöÄ Logistic Regression\n","logreg = LogisticRegression(random_state=42)\n","logreg.fit(X_train_resampled, y_train_resampled)\n","y_pred_logreg = logreg.predict(X_test)\n","print(\"\\nüîç Logistic Regression Evaluation:\")\n","print(f\"Accuracy: {accuracy_score(y_test, y_pred_logreg) * 100:.2f}%\")\n","print(classification_report(y_test, y_pred_logreg, target_names=['Not at risk (0)', 'At risk (1)']))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logreg))\n","\n","# üöÄ Decision Tree\n","dtree = DecisionTreeClassifier(random_state=42)\n","dtree.fit(X_train_resampled, y_train_resampled)\n","y_pred_dtree = dtree.predict(X_test)\n","print(\"\\nüîç Decision Tree Evaluation:\")\n","print(f\"Accuracy: {accuracy_score(y_test, y_pred_dtree) * 100:.2f}%\")\n","print(classification_report(y_test, y_pred_dtree, target_names=['Not at risk (0)', 'At risk (1)']))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dtree))\n","\n","# üöÄ Random Forest\n","rf = RandomForestClassifier(random_state=42)\n","rf.fit(X_train_resampled, y_train_resampled)\n","y_pred_rf = rf.predict(X_test)\n","print(\"\\nüîç Random Forest Evaluation:\")\n","print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf) * 100:.2f}%\")\n","print(classification_report(y_test, y_pred_rf, target_names=['Not at risk (0)', 'At risk (1)']))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n","\n","# üöÄ XGBoost\n","xgb = XGBClassifier(random_state=42)\n","xgb.fit(X_train_resampled, y_train_resampled)\n","y_pred_xgb = xgb.predict(X_test)\n","print(\"\\nüîç XGBoost Evaluation:\")\n","print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb) * 100:.2f}%\")\n","print(classification_report(y_test, y_pred_xgb, target_names=['Not at risk (0)', 'At risk (1)']))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SU2wUIUY9FTZ","executionInfo":{"status":"ok","timestamp":1750433323459,"user_tz":-360,"elapsed":1842,"user":{"displayName":"Faria Ahmed Richi","userId":"06940165953230423654"}},"outputId":"e385737c-2fc1-47aa-88db-288e407dfbd9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]}]}